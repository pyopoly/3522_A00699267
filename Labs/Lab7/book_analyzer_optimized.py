"""
This module is responsible for holding a badly written (but not so bad
that you won't find this in the workplace) BookAnalyzer class that needs
to be profiled and optimized.
"""

__author__ = "Jack Shih"
__version__ = "Jan 2021"

"""

Changes made:
Used generator expressions in read_data(self, src="House of Usher.txt").
Used dictionary instead to store the words as keys in the dictionary, since keys must be unique, 
there is no need to check for unique words anymore.
Deleted is_unique(word, word_list).
"""

import pstats, cProfile, io


def profile(fnc):
    """
    An implementation of a function decorator that wraps a function in
    a code that profiles it.
    """

    def inner(*args, **kwargs):
        pr = cProfile.Profile()
        pr.enable()

        # wrapped function starts
        retval = fnc(*args, **kwargs)  # fnc is whatever function has the @profile tag
        # wrapped function ends

        pr.disable()
        s = io.StringIO()
        sortby = pstats.SortKey.CALLS
        ps = pstats.Stats(pr, stream=s).strip_dirs().sort_stats(sortby)
        ps.print_stats()
        print(s.getvalue())
        return retval

    return inner


class BookAnalyzer:
    """
    This class provides the ability to load the words in a text file in
    memory and provide the ability to filter out the words that appear
    only once.
    """

    # a constant to help filter out common punctuation.
    COMMON_PUNCTUATION = [",", "*", ";", ".", ":", "(", "[", "]", ")"]

    def __init__(self):
        self.text = None

    # @profile
    def read_data(self, src="House of Usher.txt"):
        """
        Reads through a text file and loads in all the words. This
        function also processes the words such that all whitespace and
        common punctuation is removed.
        :param src: the name of the file, a string
        """
        # read lines
        with open(src, mode='r', encoding='utf-8') as book_file:
            text = book_file.readlines()

        # if line != '\n' is not needed as it an empty list is generated by split(),
        # and since there is no word in the list, it is skipped.
        words = (word for line in text for word in line.lower().split())

        common_punctuation = self.COMMON_PUNCTUATION
        temp_text = {}
        for word in words:
            for punctuation in common_punctuation:
                if punctuation in word:
                    word = word.replace(punctuation, '')
            temp_text[word] = None

        self.text = temp_text

    # @staticmethod
    # def is_unique(word, word_list):
    #     """
    #     Checks to see if the given word appears in the provided sequence.
    #     This check is case in-sensitive.
    #     :param word: a string
    #     :param word_list: a sequence of words
    #     :return: True if not found, false otherwise
    #     """
    #     for a_word in word_list:
    #         if word == a_word:
    #             return False
    #     return True

    # @profile
    def find_unique_words(self):
        """
        Filters out all the words that only appear once in the text.
        :return: a list of all the unique words.
        """
        temp_text = self.text
        return list(unique_word for unique_word in temp_text.keys())


@profile
def main():
    book_analyzer = BookAnalyzer()
    book_analyzer.read_data()
    unique_words = book_analyzer.find_unique_words()
    print("-" * 50)
    print(f"List of unique words (Count: {len(unique_words)})")
    print("-" * 50)
    for word in unique_words:
        print(word)
    print("-" * 50)


if __name__ == '__main__':
    main()
